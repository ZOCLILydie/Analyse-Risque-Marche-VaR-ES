{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Télécharger les données de Yahoo Finance\n",
    "tickers = [\"JPM\", \"AIG\", \"GS\"]\n",
    "start_date = \"2007-01-01\"\n",
    "end_date = \"2023-12-31\"\n",
    "\n",
    "# Initialisation du dictionnaire pour stocker les données\n",
    "data = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    print(f\"Téléchargement des données pour {ticker}...\")\n",
    "    stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    \n",
    "    # Vérifier si des données sont disponibles\n",
    "    if not stock_data.empty:\n",
    "        data[ticker] = stock_data['Close']\n",
    "    else:\n",
    "        print(f\"Aucune donnée trouvée pour {ticker}.\")\n",
    "\n",
    "# Vérifier si 'data' contient des données valides\n",
    "if data:\n",
    "    # Combiner les données en un DataFrame\n",
    "    adjusted_prices = pd.concat(data.values(), axis=1)\n",
    "    adjusted_prices.columns = data.keys()  # Nommer les colonnes avec les tickers\n",
    "    adjusted_prices.index.name = \"Date\"   # Nommer l'index\n",
    "    adjusted_prices.reset_index(inplace=True)\n",
    "\n",
    "    # Sauvegarder les prix ajustés\n",
    "    adjusted_prices.to_csv(\"adjusted_prices.csv\", index=False)\n",
    "    print(\"Données sauvegardées dans 'adjusted_prices.csv'.\")\n",
    "else:\n",
    "    print(\"Aucune donnée valide n'a été trouvée pour les tickers spécifiés.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "\n",
    "# Charger la base de données à partir du fichier CSV\n",
    "adjusted_prices = pd.read_csv(\"adjusted_prices.csv\")\n",
    "\n",
    "# Afficher les premières lignes de la base de données\n",
    "print(\"Aperçu des premières lignes :\")\n",
    "print(adjusted_prices.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les prix ajustés\n",
    "adjusted_prices = pd.read_csv(\"adjusted_prices.csv\")\n",
    "adjusted_prices['Date'] = pd.to_datetime(adjusted_prices['Date'])\n",
    "\n",
    "# Calculer les rendements logarithmiques\n",
    "log_returns = adjusted_prices.copy()\n",
    "for ticker in tickers:\n",
    "    log_returns[ticker] = np.log(adjusted_prices[ticker] / adjusted_prices[ticker].shift(1))\n",
    "\n",
    "# Supprimer les valeurs manquantes\n",
    "log_returns.dropna(inplace=True)\n",
    "\n",
    "# Sauvegarder les rendements\n",
    "log_returns.to_csv(\"log_returns.csv\", index=False)\n",
    "\n",
    "print(log_returns.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from arch import arch_model\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kurtosis, skew, jarque_bera\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from arch import arch_model\n",
    "\n",
    "# Load log returns\n",
    "log_returns = pd.read_csv(\"Log_Returns.csv\", parse_dates=[\"Date\"])\n",
    "log_returns.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# Extract institutions\n",
    "JPM = log_returns[\"JPM\"].dropna()\n",
    "AIG = log_returns[\"AIG\"].dropna()\n",
    "GS = log_returns[\"GS\"].dropna()\n",
    "\n",
    "# Calculate skewness and kurtosis\n",
    "print(\"Skewness:\")\n",
    "print(f\"JPM: {skew(JPM):.6f}\")\n",
    "print(f\"AIG: {skew(AIG):.6f}\")\n",
    "print(f\"GS: {skew(GS):.6f}\")\n",
    "\n",
    "print(\"\\nKurtosis:\")\n",
    "print(f\"JPM: {kurtosis(JPM, fisher=False):.6f}\")\n",
    "print(f\"AIG: {kurtosis(AIG, fisher=False):.6f}\")\n",
    "print(f\"GS: {kurtosis(GS, fisher=False):.6f}\")\n",
    "\n",
    "# Define a function to estimate GARCH models\n",
    "def estimate_garch(data, dist):\n",
    "    return arch_model(data, vol=\"Garch\", p=1, q=1, mean=\"Zero\", dist=dist).fit(disp=\"off\")\n",
    "\n",
    "# Distributions to test\n",
    "distributions = [\"normal\", \"t\", \"ged\"]\n",
    "\n",
    "# Function to collect model metrics\n",
    "def model_metrics(model):\n",
    "    residuals = model.resid / model.conditional_volatility\n",
    "    return {\n",
    "        \"Omega\": model.params[\"omega\"],\n",
    "        \"Alpha1\": model.params[\"alpha[1]\"],\n",
    "        \"Beta1\": model.params[\"beta[1]\"],\n",
    "        \"Shape\": model.params.get(\"nu\", model.params.get(\"lambda\", None)),\n",
    "        \"AIC\": model.aic,\n",
    "        \"BIC\": model.bic,\n",
    "        \"LogLik\": model.loglikelihood,\n",
    "        \"LjungBox_p\": acorr_ljungbox(residuals, lags=[10], return_df=True)[\"lb_pvalue\"].iloc[0]\n",
    "    }\n",
    "\n",
    "# Diagnostic checks\n",
    "def diagnostic_checks(model):\n",
    "    residuals = model.resid / model.conditional_volatility\n",
    "    return {\n",
    "        \"LjungBox_Std\": acorr_ljungbox(residuals, lags=[10], return_df=True)[\"lb_pvalue\"].iloc[0],\n",
    "        \"LjungBox_Sq\": acorr_ljungbox(residuals**2, lags=[10], return_df=True)[\"lb_pvalue\"].iloc[0],\n",
    "        \"JB_p\": jarque_bera(residuals)[1],\n",
    "        \"Skewness\": skew(residuals),\n",
    "        \"Kurtosis\": kurtosis(residuals, fisher=False)\n",
    "    }\n",
    "\n",
    "# Estimation for each institution\n",
    "results = {}\n",
    "for ticker, data in {\"JPM\": JPM, \"AIG\": AIG, \"GS\": GS}.items():\n",
    "    print(f\"\\nEstimating GARCH models for {ticker}...\")\n",
    "    volatility_est = {dist: estimate_garch(data, dist) for dist in distributions}\n",
    "    metrics = {dist: model_metrics(model) for dist, model in volatility_est.items()}\n",
    "    diagnostics = {dist: diagnostic_checks(model) for dist, model in volatility_est.items()}\n",
    "    results[ticker] = {\n",
    "        \"metrics\": pd.DataFrame(metrics).T,\n",
    "        \"diagnostics\": pd.DataFrame(diagnostics).T\n",
    "    }\n",
    "\n",
    "# Print results\n",
    "for ticker, result in results.items():\n",
    "    print(f\"\\nMetrics for {ticker}:\")\n",
    "    print(result[\"metrics\"].round(6))\n",
    "    print(f\"\\nDiagnostics for {ticker}:\")\n",
    "    print(result[\"diagnostics\"].round(6))\n",
    "\n",
    "# Plotting\n",
    "def plot_diagnostics(ticker, models):\n",
    "    dist_full_names = {\n",
    "        \"normal\": \"Normal Distribution\",\n",
    "        \"t\": \"Student-t Distribution\",\n",
    "        \"ged\": \"Generalized Error Distribution\"\n",
    "    }\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for dist, model in models.items():\n",
    "        residuals = model.resid / model.conditional_volatility\n",
    "        plt.subplot(3, 3, list(models.keys()).index(dist) * 3 + 1)\n",
    "        plt.title(f\"{ticker} - Q-Q Plot ({dist_full_names[dist]})\")\n",
    "        qq = np.sort(residuals)\n",
    "        plt.plot(qq, np.sort(np.random.normal(0, 1, len(qq))), 'o', alpha=0.5)\n",
    "        plt.plot([-3, 3], [-3, 3], 'r--')\n",
    "        plt.subplot(3, 3, list(models.keys()).index(dist) * 3 + 2)\n",
    "        plt.title(f\"{ticker} - ACF ({dist_full_names[dist]})\")\n",
    "        plt.acorr(residuals, maxlags=10)\n",
    "        plt.subplot(3, 3, list(models.keys()).index(dist) * 3 + 3)\n",
    "        plt.title(f\"{ticker} - ACF of Squared Residuals ({dist_full_names[dist]})\")\n",
    "        plt.acorr(residuals**2, maxlags=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for ticker, data in {\"JPM\": JPM, \"AIG\": AIG, \"GS\": GS}.items():\n",
    "    plot_diagnostics(ticker, {dist: estimate_garch(data, dist) for dist in distributions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from arch import arch_model\n",
    "from scipy.stats import t, norm\n",
    "\n",
    "# 1. Load the data\n",
    "log_returns = pd.read_csv(\"Log_Returns.csv\", index_col=\"Date\", parse_dates=True)\n",
    "\n",
    "# 2. Parameters\n",
    "alpha = 0.05  # 5% risk level\n",
    "rolling_windows = [250, 500]  # 250-day and 500-day rolling window\n",
    "institutions = [\"JPM\", \"AIG\", \"GS\"]\n",
    "\n",
    "# 3. Define the best models for each institution\n",
    "models = {\n",
    "    \"JPM\": \"Garch\",   # GARCH(1,1) with Student-t distribution\n",
    "    \"AIG\": \"EGarch\",  # EGARCH(1,1) with Skew Student-t distribution\n",
    "    \"GS\": \"Garch\"     # GARCH(1,1) with Student-t distribution\n",
    "}\n",
    "\n",
    "# 4. Define the best distribution for each institution\n",
    "distributions = {\n",
    "    \"JPM\": \"studentst\",\n",
    "    \"AIG\": \"ged\",  # Skew Student-t is not directly supported in arch package\n",
    "    \"GS\": \"studentst\"\n",
    "}\n",
    "\n",
    "# 5. Store results\n",
    "results = {}\n",
    "figure_number = 1  # Initialize figure numbering\n",
    "\n",
    "# 6. Loop over institutions and rolling windows\n",
    "for inst in institutions:\n",
    "    print(f\"Processing {inst}...\")\n",
    "\n",
    "    for rolling_window in rolling_windows:\n",
    "        returns = log_returns[inst].dropna()\n",
    "        VaR_HS = []\n",
    "        VaR_GARCH = []\n",
    "        forecast_dates = []\n",
    "\n",
    "        # Rolling window estimation\n",
    "        for i in range(rolling_window, len(returns)):\n",
    "            # Define rolling data\n",
    "            rolling_data = returns.iloc[i - rolling_window:i]\n",
    "\n",
    "            # Store forecast date\n",
    "            forecast_dates.append(returns.index[i])\n",
    "\n",
    "            # Historical Simulation VaR\n",
    "            VaR_HS.append(np.percentile(rolling_data, alpha * 100))\n",
    "\n",
    "            # Fit GARCH model\n",
    "            spec = arch_model(\n",
    "                rolling_data,\n",
    "                vol=models[inst],\n",
    "                p=1,\n",
    "                q=1,\n",
    "                dist=distributions[inst],\n",
    "                mean=\"Zero\"\n",
    "            )\n",
    "            model = spec.fit(disp=\"off\")\n",
    "\n",
    "            # Forecast conditional volatility\n",
    "            sigma_forecast = model.conditional_volatility[-1]\n",
    "\n",
    "            # GARCH VaR\n",
    "            VaR_GARCH.append(\n",
    "                sigma_forecast * t.ppf(alpha, df=5) if distributions[inst] == \"studentst\" \n",
    "                else sigma_forecast * norm.ppf(alpha)\n",
    "            )\n",
    "\n",
    "        # Store results\n",
    "        results[(inst, rolling_window)] = pd.DataFrame({\n",
    "            \"Date\": forecast_dates,\n",
    "            \"VaR_HS\": VaR_HS,\n",
    "            \"VaR_GARCH\": VaR_GARCH\n",
    "        }).set_index(\"Date\")\n",
    "\n",
    "        # Plot results\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(results[(inst, rolling_window)].index, results[(inst, rolling_window)][\"VaR_HS\"], \n",
    "                 label=f\"VaR HS ({rolling_window}-day)\", linestyle=\"--\", color=\"blue\")\n",
    "        plt.plot(results[(inst, rolling_window)].index, results[(inst, rolling_window)][\"VaR_GARCH\"], \n",
    "                 label=f\"VaR GARCH ({rolling_window}-day)\", linestyle=\"--\", color=\"red\")\n",
    "        plt.plot(log_returns.loc[results[(inst, rolling_window)].index, inst], \n",
    "                 label=\"Returns\", color=\"black\", alpha=0.5)\n",
    "        plt.xlabel(\"Date\", fontsize=12)\n",
    "        plt.ylabel(\"Values\", fontsize=12)\n",
    "        plt.legend(fontsize=10)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Add title as figure caption at the bottom\n",
    "        title = f\"Fig. {figure_number} — VaR Forecasts for {inst} using a {rolling_window}-day Rolling Window\"\n",
    "        plt.figtext(0.5, -0.05, title, wrap=True, horizontalalignment='center', fontsize=10)\n",
    "        plt.show()\n",
    "\n",
    "        # Increment the figure number\n",
    "        figure_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from arch import arch_model\n",
    "from scipy.stats import t, norm\n",
    "\n",
    "# 1. Load the data\n",
    "log_returns = pd.read_csv(\"Log_Returns.csv\", index_col=\"Date\", parse_dates=True)\n",
    "\n",
    "# 2. Parameters\n",
    "alpha = 0.05  # 5% risk level\n",
    "rolling_windows = [250, 500]  # 250-day and 500-day rolling window\n",
    "institutions = [\"JPM\", \"AIG\", \"GS\"]\n",
    "\n",
    "# 3. Define the best models for each institution\n",
    "models = {\n",
    "    \"JPM\": \"Garch\",   # GARCH(1,1) with Student-t distribution\n",
    "    \"AIG\": \"EGarch\",  # EGARCH(1,1) with Skew Student-t distribution\n",
    "    \"GS\": \"Garch\"     # GARCH(1,1) with Student-t distribution\n",
    "}\n",
    "\n",
    "# 4. Define the best distribution for each institution\n",
    "distributions = {\n",
    "    \"JPM\": \"studentst\",\n",
    "    \"AIG\": \"ged\",  # Skew Student-t is not directly supported in arch package\n",
    "    \"GS\": \"studentst\"\n",
    "}\n",
    "\n",
    "# 5. Store results\n",
    "results = {}\n",
    "figure_number = 7  # Start numbering figures from 7\n",
    "\n",
    "# 6. Loop over institutions and rolling windows\n",
    "for inst in institutions:\n",
    "    print(f\"Processing {inst}...\")\n",
    "\n",
    "    for rolling_window in rolling_windows:\n",
    "        returns = log_returns[inst].dropna()\n",
    "        ES_HS = []\n",
    "        ES_GARCH = []\n",
    "        forecast_dates = []\n",
    "\n",
    "        # Rolling window estimation\n",
    "        for i in range(rolling_window, len(returns)):\n",
    "            # Define rolling data\n",
    "            rolling_data = returns.iloc[i - rolling_window:i]\n",
    "\n",
    "            # Store forecast date\n",
    "            forecast_dates.append(returns.index[i])\n",
    "\n",
    "            # Historical Simulation ES\n",
    "            below_threshold = rolling_data[rolling_data <= np.percentile(rolling_data, alpha * 100)]\n",
    "            ES_HS.append(np.mean(below_threshold) if len(below_threshold) > 0 else None)\n",
    "\n",
    "            # Fit GARCH model\n",
    "            spec = arch_model(\n",
    "                rolling_data,\n",
    "                vol=models[inst],\n",
    "                p=1,\n",
    "                q=1,\n",
    "                dist=distributions[inst],\n",
    "                mean=\"Zero\"\n",
    "            )\n",
    "            model = spec.fit(disp=\"off\")\n",
    "\n",
    "            # Forecast conditional volatility\n",
    "            sigma_forecast = model.conditional_volatility[-1]\n",
    "\n",
    "            # GARCH ES Calculation\n",
    "            if distributions[inst] == \"studentst\":\n",
    "                ES_GARCH.append(-sigma_forecast * (t.pdf(t.ppf(alpha, df=5), df=5) / alpha))\n",
    "            else:\n",
    "                ES_GARCH.append(-sigma_forecast * (norm.pdf(norm.ppf(alpha)) / alpha))\n",
    "\n",
    "        # Store results\n",
    "        results[(inst, rolling_window)] = pd.DataFrame({\n",
    "            \"Date\": forecast_dates,\n",
    "            \"ES_HS\": ES_HS,\n",
    "            \"ES_GARCH\": ES_GARCH\n",
    "        }).set_index(\"Date\")\n",
    "\n",
    "        # Plot results\n",
    "        data = results[(inst, rolling_window)]  # Correctly retrieve the stored data\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(data.index, data[\"ES_HS\"], label=f\"ES HS ({rolling_window}-day)\", linestyle=\"--\", color=\"blue\")\n",
    "        plt.plot(data.index, data[\"ES_GARCH\"], label=f\"ES GARCH ({rolling_window}-day)\", linestyle=\"--\", color=\"red\")\n",
    "        plt.plot(log_returns.loc[data.index, inst], label=\"Returns\", color=\"black\", alpha=0.5)\n",
    "        plt.xlabel(\"Date\", fontsize=12)\n",
    "        plt.ylabel(\"Returns / ES\", fontsize=12)\n",
    "        plt.legend(fontsize=10)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Add title as figure caption at the bottom\n",
    "        title = f\"Fig. {figure_number} — Forecast for ES using a {rolling_window}-day Rolling Window for {inst}\"\n",
    "        plt.figtext(0.5, -0.05, title, wrap=True, horizontalalignment='center', fontsize=10)\n",
    "        plt.show()\n",
    "\n",
    "        # Increment the figure number\n",
    "        figure_number += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
